Christos-Nikolaos Mitsopoulos
11/30/2017

----------------------
Purpose of the program
----------------------
This program indexes and searches a directory for a specified
string (basically like the grep unix program).

--------------
Files provided
-------------- 
-WordHasher.h -> The WordHasher class header and function definitions
-WordHasher.cpp -> The WordHasher class implementation that
					contains declarations of functions
-main.cpp -> The script for the final executable
-entryStructs.h -> The structs used for word indexing
-stringProcessing.h -> Function declaration for stringProcessing function
-stringProcessing.cpp -> Function definition for above
-Makefile -> The instructions for "make" to compile the program

-----------------
Low-Level Details
-----------------
To compile the program, simply type "make" in the command line window.
To run the program, type the following in the command line

./gerp [DirectoryToIndex]

-where DirectoryToIndex determines which directory will be traversed
and indexed. You could use "/comp/15/files" for example.

After this, the program will prompt you for a query where you type:
	-> A string
	-> @i and a string (or @insensitive) will do a case insensitive
		search.
	-> @q or @quit will quit the program.

----------------------
Architectural Overview
----------------------
The WordHasher class utilizes the FSTree implementation and represents
the input directory as a tree with a pointer to its DirNode root. The
tree is then traversed using a pointer to the root of the subtree each
time. The hashtable implemented using the WordHasher class is based
on the structs found in entryStructs.h, as the sequence that represents
the hashtable consists of Entry node pointers. Pointers were chosen
so that when an index is empty, the node in that index points to null.

--------------------------
Outline of Data Structures
--------------------------
The indexing part of this project was completed using a hashtable implemented
in the WordHasher class. The hashtable is represented by a dynamic array
of Entry struct pointers. My implementation uses the built in STL function
std::hash and generates an index by inputting a string. Collisions are 
then handled using the chaining method. That is, every index in the sequence 
contains a linked list. In order to better understand the way information
about words is stored in the hashtable and how it is added, it is prudent
to understand what information is needed for every word in the query:
When printing query results we need:
	-Full file path
	-The word itself
	-The line number
	-The full line where the word is found
	-In the case of insensitive search, all variations of the word found.

** How is all this data stored in the table? **

The hashtable stores entry struct pointers. An entry struct pointer
consists of -> All lowercase version of the word(basically a string 
				that represents the key and this is what is hashed)
			-> A vector of WordInfo nodes which consist of:
				-> A string that represents the original word found in file
				-> A vector of LocInfo nodes which consist of:
					-> The full filepath in a string
					-> The line number of the word in the file.
			-> A pointer to the next entry node.

To sum up, each index in the hashtable contains an all lowercase version
of a word, a vector of all the different variations(capitalizations) of
this word found in the directory and a vector of all the different 
locations of all the different variations found.

** Why did I choose this data structure? ** 

A hashtable was chosen for very fast retrieval of information once the
key (lowercase version of word) is known (sequential access of array).

In terms of what is stored in the table:

Think about the case where two words are the same in an all lowercase
version, but have different capitalizations. If you are talking about
large directories with a large amount of files, this happens really 
often. Now imagine if each different word variation was in an entirely
different index. This would lead into an extremely large array and 
a large amount of indexes which is memory inefficient. By storing
different variations in the same struct, this problem is eliminated.

** How do I handle collisions? ** 

Collisions are handled by implementing a linked list structure at every
index. The way this is done is, each Entry node contains a pointer to 
another entry node (or NULL) as in a linked list. Therefore, multiple
different keys can co-exist in the same index (however performance
decreases if linked list has to be traversed to find a query because
there is no sequential access).

** How do I make the querying faster? **

Every 10 files, my program checks whether the hashtable needs to be 
expanded and rehashed in order to reduce the length of linked lists
in indexes (which leads to faster querying in the end, although
indexing slows down a bit). The algorithm, chooses that an expansion
is required, if the load factor (ratio of entries to array size) 
is greater than 0.7.

** What could I improve in this algorithm? **

Right now, even if two words are exactly the same, a new location entry
is created everytime. I chose this instead of looping through the location
vector and seeing if the same location is already added because looping 
through each location vector was very time consuming.

** What algorithm did I use for querying? **

For querying, my algorithm opens the filepath, goes to the required
line number and just prints the file line in the appropriate content.

** Memory vs time usage **

For my algorithm, I chose faster runtime instead of low memory usage.
I think this was an appropriate choice regarding the deliverables of 
this project, as I was below the maximum RAM usage and my indexing was
really fast. For comparison, here are my results for the largeGutenberg
directory:
-> User time (seconds): 46.39
-> Maximum resident set size (kbytes): 7953164 -> 8gb

--------
Testing
--------
The testing for this project is mostly based on trial and error. Here are some
of the testing methods I used:
Initially,

-For file traversal:
I created many directories with subdirectories inside them and empty files.
I then printed and opened all filenames and checked my results against Linux's
ls command.

-For addition function:
I created printTable() that prints the entries currently in the hashtable along
with other useful information such as line number in which word is found,
along with all its different variations. Using this function I tested all
the different cases of addition and checked the results. After this I checked
edge cases such as when a string is full of nonalphanumerical characters.

I then created a sample Directory with a single file in it and filled the file
with sample tests such as:
	-Same word different variations
	-Same word same line

-For general functionality:
Run the testHasher.cpp using clang++ -Wall -Wextra -std=c++11 testHasher.cpp
This program compares the ouput of the reference implementation to my
implementation. To choose the commands you want the implementation to run,
change the file commands.txt and then run it. If the program prints that
there are no differences, my implementation works!

